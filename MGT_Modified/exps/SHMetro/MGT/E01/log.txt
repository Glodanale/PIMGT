Start time: 2024-10-04 15:02:58.823776
---------- Args ----------
{
  "dataset": "SHMetro",
  "model": "MGT",
  "name": "E01",
  "gpu": "0",
  "batch_size": 16,
  "num_workers": 1,
  "lr": 0.001,
  "eps": 1e-08,
  "weight_decay": 0.0002,
  "milestones": [
    50,
    80
  ],
  "gamma": 0.1,
  "epochs": 100,
  "val_freq": 1,
  "clip_grad_norm": false,
  "max_grad_norm": 5,
  "test": false,
  "save_every": 101,
  "dataset_model_args": {
    "dataset": {
      "root": "data/SHMetro",
      "eigenmaps_k": 8,
      "similarity_delta": 0.1
    },
    "model": {
      "d_model": 16,
      "d_k": 4,
      "d_hidden_mt": 16,
      "d_hidden_ff": 16,
      "eigenmaps_k": 8,
      "num_embeddings": [
        73,
        2
      ],
      "num_features": 2,
      "num_encoder_layers": 6,
      "num_decoder_layers": 6,
      "num_heads": 4,
      "which_transition_matrices": [
        true,
        true,
        true
      ],
      "in_len": 4,
      "out_len": 4,
      "use_curriculum_learning": false,
      "cl_decay_steps": 200,
      "dropout": 0.3,
      "noTSA": false,
      "noSSA": false,
      "noMeta": false,
      "noTE": false,
      "noSE": false
    }
  },
  "exp_dir": "exps/SHMetro/MGT/E01"
}
--------- Model Info ---------
Model size: 2.803784MB
---------- Training ----------
num_samples: 4092, num_batches: 255
Start time: 2024-10-04 15:04:01.046938
---------- Args ----------
{
  "dataset": "SHMetro",
  "model": "MGT",
  "name": "E01",
  "gpu": "0",
  "batch_size": 16,
  "num_workers": 8,
  "lr": 0.001,
  "eps": 1e-08,
  "weight_decay": 0.0002,
  "milestones": [
    50,
    80
  ],
  "gamma": 0.1,
  "epochs": 100,
  "val_freq": 1,
  "clip_grad_norm": false,
  "max_grad_norm": 5,
  "test": false,
  "save_every": 101,
  "dataset_model_args": {
    "dataset": {
      "root": "data/SHMetro",
      "eigenmaps_k": 8,
      "similarity_delta": 0.1
    },
    "model": {
      "d_model": 16,
      "d_k": 4,
      "d_hidden_mt": 16,
      "d_hidden_ff": 16,
      "eigenmaps_k": 8,
      "num_embeddings": [
        73,
        2
      ],
      "num_features": 2,
      "num_encoder_layers": 6,
      "num_decoder_layers": 6,
      "num_heads": 4,
      "which_transition_matrices": [
        true,
        true,
        true
      ],
      "in_len": 4,
      "out_len": 4,
      "use_curriculum_learning": false,
      "cl_decay_steps": 200,
      "dropout": 0.3,
      "noTSA": false,
      "noSSA": false,
      "noMeta": false,
      "noTE": false,
      "noSE": false
    }
  },
  "exp_dir": "exps/SHMetro/MGT/E01"
}
--------- Model Info ---------
Model size: 2.803784MB
---------- Training ----------
num_samples: 4092, num_batches: 255
